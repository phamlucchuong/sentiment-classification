import joblib
import torch
from transformers import AutoModel, AutoTokenizer

# ----------------------------------------------------
# 1. Táº¢I CÃC MODEL (giá»‘ng há»‡t predictor.py)
# ----------------------------------------------------
print("Äang táº£i model...")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Táº£i PhoBERT
PHOBERT_MODEL_NAME = "vinai/phobert-base"
phobert_tokenizer = AutoTokenizer.from_pretrained(PHOBERT_MODEL_NAME)
phobert_model = AutoModel.from_pretrained(PHOBERT_MODEL_NAME)
phobert_model.to(device)
phobert_model.eval()

# Táº£i model Logistic Regression (Ä‘Æ°á»ng dáº«n tá»›i file pkl)
# HÃ£y cháº¯c cháº¯n Ä‘Æ°á»ng dáº«n nÃ y lÃ  Ä‘Ãºng
MODEL_FILE_PATH = "models/best_sentiment_model.pkl" 
lr_model = joblib.load(MODEL_FILE_PATH)

print("Táº£i model thÃ nh cÃ´ng!")

# ----------------------------------------------------
# 2. HÃ€M Dá»° ÄOÃN (giá»‘ng há»‡t predictor.py)
# ----------------------------------------------------
def get_sentiment(text: str) -> tuple:
    """
    Tráº£ vá» (label_sá»‘, label_text, probability) Ä‘á»ƒ dá»… theo dÃµi
    """
    # 1. Tokenize
    inputs = phobert_tokenizer(
        text, 
        add_special_tokens=True, 
        max_length=256, 
        padding='max_length', 
        truncation=True, 
        return_tensors='pt'
    )
    
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    # 2. Láº¥y embedding
    with torch.no_grad():
        outputs = phobert_model(input_ids=input_ids, attention_mask=attention_mask)
        cls_embedding = outputs[0][:, 0, :].cpu().numpy()

    # 3. Dá»± Ä‘oÃ¡n
    prediction = lr_model.predict(cls_embedding)
    
    # Láº¥y xÃ¡c suáº¥t náº¿u model há»— trá»£
    try:
        probabilities = lr_model.predict_proba(cls_embedding)[0]
        confidence = max(probabilities)
    except:
        confidence = None
    
    # 4. Tráº£ vá» káº¿t quáº£ vá»›i label sá»‘ vÃ  text
    label_num = int(prediction[0])
    if label_num == 1:
        label_text = "TÃ­ch cá»±c (Positive)"
    elif label_num == 0:
        label_text = "TiÃªu cá»±c (Negative)"
    else:
        label_text = f"KhÃ´ng xÃ¡c Ä‘á»‹nh (Label={label_num})"
    
    return label_num, label_text, confidence

# ----------------------------------------------------
# 3. KIá»‚M THá»¬ TOÃ€N DIá»†N
# ----------------------------------------------------
if __name__ == "__main__":
    
    # Test cases Ä‘a dáº¡ng Ä‘á»ƒ kiá»ƒm tra model dá»± Ä‘oÃ¡n Ä‘Æ°á»£c máº¥y nhÃ£n
    test_cases = [
        # Positive rÃµ rÃ ng
        ("MÃ³n Äƒn ráº¥t ngon, phá»¥c vá»¥ tuyá»‡t vá»i, tÃ´i sáº½ quay láº¡i", "Positive"),
        ("Tuyá»‡t vá»i, khÃ´ng cÃ³ gÃ¬ Ä‘á»ƒ chÃª", "Positive"),
        ("Sáº£n pháº©m cháº¥t lÆ°á»£ng, giÃ¡ cáº£ há»£p lÃ½, ráº¥t hÃ i lÃ²ng", "Positive"),
        ("Äá»“ Äƒn tÆ°Æ¡i ngon, nhÃ¢n viÃªn thÃ¢n thiá»‡n, khÃ´ng gian Ä‘áº¹p", "Positive"),
        
        # Negative rÃµ rÃ ng
        ("QuÃ¡n nÃ y tá»‡ láº¯m, Ä‘á»“ Äƒn dá»Ÿ, khÃ´ng bao giá» quay láº¡i", "Negative"),
        ("Shop nÃªn xem láº¡i thÃ¡i Ä‘á»™ phá»¥c vá»¥, ráº¥t tá»‡", "Negative"),
        ("MÃ³n Äƒn cá»±c tá»‡, cháº¥t lÆ°á»£ng kÃ©m", "Negative"),
        ("Tháº¥t vá»ng, lÃ£ng phÃ­ tiá»n, khÃ´ng nÃªn Ä‘áº¿n", "Negative"),
        ("Äá»“ Äƒn nguá»™i láº¡nh, chá» lÃ¢u, nhÃ¢n viÃªn thá» Æ¡", "Negative"),
        
        # Trung tÃ­nh /ì• ë§¤í•œ trÆ°á»ng há»£p
        ("Sáº£n pháº©m nÃ y dÃ¹ng cÅ©ng táº¡m Ä‘Æ°á»£c", "Neutral/Unclear"),
        ("BÃ¬nh thÆ°á»ng, khÃ´ng cÃ³ gÃ¬ Ä‘áº·c biá»‡t", "Neutral/Unclear"),
        ("GiÃ¡ hÆ¡i cao nhÆ°ng cÅ©ng Ä‘Æ°á»£c", "Neutral/Unclear"),
    ]
    
    print("=" * 80)
    print("ğŸ§ª KIá»‚M THá»¬ MODEL - Dá»° ÄOÃN ÄÆ¯á»¢C BAO NHIÃŠU NHÃƒN?")
    print("=" * 80)
    print(f"ğŸ“Š Model: {MODEL_FILE_PATH}")
    print(f"ğŸ–¥ï¸  Device: {device}")
    print("=" * 80)
    
    # Thá»‘ng kÃª káº¿t quáº£
    predictions_count = {}
    results = []
    
    print("\nğŸ“ Káº¾T QUáº¢ Dá»° ÄOÃN CHI TIáº¾T:")
    print("-" * 80)
    
    for i, (text, expected_type) in enumerate(test_cases, 1):
        label_num, label_text, confidence = get_sentiment(text)
        
        # Äáº¿m cÃ¡c label
        predictions_count[label_num] = predictions_count.get(label_num, 0) + 1
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        conf_str = f"{confidence:.2%}" if confidence else "N/A"
        print(f"\n[Test {i:2d}] Loáº¡i mong Ä‘á»£i: {expected_type}")
        print(f"  ğŸ“„ Input: '{text[:60]}{'...' if len(text) > 60 else ''}'")
        print(f"  ğŸ¯ Dá»± Ä‘oÃ¡n: Label={label_num} | {label_text} | Confidence={conf_str}")
        
        results.append({
            'text': text,
            'expected': expected_type,
            'label': label_num,
            'label_text': label_text,
            'confidence': confidence
        })
    
    # Thá»‘ng kÃª tá»•ng quan
    print("\n" + "=" * 80)
    print("ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
    print("=" * 80)
    print(f"âœ… Tá»•ng sá»‘ test cases: {len(test_cases)}")
    print(f"ğŸ·ï¸  Sá»‘ nhÃ£n duy nháº¥t Ä‘Æ°á»£c dá»± Ä‘oÃ¡n: {len(predictions_count)}")
    print(f"\nğŸ“ˆ PhÃ¢n bá»‘ dá»± Ä‘oÃ¡n:")
    for label, count in sorted(predictions_count.items()):
        label_name = "Negative (0)" if label == 0 else "Positive (1)" if label == 1 else f"Unknown ({label})"
        percentage = count / len(test_cases) * 100
        print(f"   - {label_name}: {count} cases ({percentage:.1f}%)")
    
    # Kiá»ƒm tra xem model cÃ³ dá»± Ä‘oÃ¡n cáº£ 2 nhÃ£n khÃ´ng
    print("\n" + "=" * 80)
    if len(predictions_count) >= 2:
        print("âœ… Káº¾T LUáº¬N: Model Dá»° ÄOÃN ÄÆ¯á»¢C NHIá»€U NHÃƒN (khÃ´ng bá»‹ overfitting hoÃ n toÃ n)")
        if 0 in predictions_count and 1 in predictions_count:
            print("âœ… Model dá»± Ä‘oÃ¡n Ä‘Æ°á»£c cáº£ 2 nhÃ£n: Negative (0) vÃ  Positive (1)")
    else:
        print("âš ï¸  Cáº¢NH BÃO: Model CHá»ˆ Dá»° ÄOÃN Má»˜T NHÃƒN DUY NHáº¤T!")
        print("   â†’ CÃ³ thá»ƒ model váº«n Ä‘ang bá»‹ overfitting nghiÃªm trá»ng")
        print("   â†’ Cáº§n huáº¥n luyá»‡n láº¡i vá»›i class_weight='balanced'")
    print("=" * 80)